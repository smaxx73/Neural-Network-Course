{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6628202c",
   "metadata": {},
   "source": [
    "# Session 6: Backpropagation\n",
    "## Teaching Neural Networks to Learn\n",
    "\n",
    "**Course: Neural Networks for Engineers**  \n",
    "**Duration: 2 hours**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Recap: What We Know So Far](#recap)\n",
    "2. [The Chain Rule: Derivatives Through Composition](#chain-rule)\n",
    "3. [Computational Graphs: Visualizing the Chain Rule](#comp-graphs)\n",
    "4. [Backpropagation: The Algorithm](#backprop)\n",
    "5. [Step-by-Step: Backprop on a 2-2-1 Network](#step-by-step)\n",
    "6. [Implementing Backpropagation from Scratch](#implementation)\n",
    "7. [Training the XOR Network (Finally!)](#xor-training)\n",
    "8. [Gradient Checking: Verifying Your Gradients](#grad-check)\n",
    "9. [Final Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Recap: What We Know So Far {#recap}\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "‚úÖ **Loss functions**: MSE measures \"how wrong\" our predictions are  \n",
    "‚úÖ **Gradient descent**: Update rule $w \\leftarrow w - \\eta \\nabla L$  \n",
    "‚úÖ **Derivatives**: The slope tells us which direction to move  \n",
    "‚úÖ **Linear regression**: Trained a single neuron with GD  \n",
    "‚úÖ **The missing piece**: How to compute gradients for **hidden layers**\n",
    "\n",
    "### ü§î Quick Questions\n",
    "\n",
    "**Q1:** In gradient descent, we update weights using $w \\leftarrow w - \\eta \\frac{\\partial L}{\\partial w}$. Why the **minus** sign?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "The gradient points in the direction of steepest **ascent** (increasing loss). We want to **decrease** the loss, so we move in the **opposite** direction.\n",
    "</details>\n",
    "\n",
    "**Q2:** For a single neuron $\\hat{y} = wx + b$, computing $\\frac{\\partial L}{\\partial w}$ was straightforward. Why is it harder for hidden layer weights?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "Hidden layer weights don't affect the loss **directly**. Changing $W^{(1)}$ changes the hidden activations $h$, which changes the output $\\hat{y}$, which changes the loss. We need to trace the effect through **multiple layers** ‚Äî this requires the **chain rule**.\n",
    "</details>\n",
    "\n",
    "**Q3:** What were the three \"think about\" questions from last session?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "1. For $f(g(x))$, we use the chain rule: $\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}$\n",
    "2. If $\\Delta h = +0.1$ causes $\\Delta L = +0.3$, then $\\frac{\\partial L}{\\partial h} \\approx 3.0$\n",
    "3. We \"pass\" the error backward by multiplying by the chain of derivatives ‚Äî this is backpropagation!\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Chain Rule: Derivatives Through Composition {#chain-rule}\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Consider a 2-layer network:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(w_2 \\cdot \\sigma(w_1 \\cdot x + b_1) + b_2)\n",
    "$$\n",
    "\n",
    "This is a **composition** of functions: the output of one feeds into the next.\n",
    "\n",
    "How do we compute $\\frac{\\partial L}{\\partial w_1}$?\n",
    "\n",
    "### The Chain Rule (Single Variable)\n",
    "\n",
    "If $y = f(g(x))$, then:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{dg} \\cdot \\frac{dg}{dx}\n",
    "$$\n",
    "\n",
    "**In words:** \"The rate of change of $y$ with respect to $x$ equals the rate of change of $y$ with respect to $g$, times the rate of change of $g$ with respect to $x$.\"\n",
    "\n",
    "### Building Intuition: A Temperature Example\n",
    "\n",
    "Suppose:\n",
    "- Temperature in ¬∞C depends on altitude: $C = 20 - 6h$ (drops 6¬∞C per km)\n",
    "- Temperature in ¬∞F depends on ¬∞C: $F = 1.8C + 32$\n",
    "\n",
    "**Question:** How fast does ¬∞F change with altitude?\n",
    "\n",
    "$$\n",
    "\\frac{dF}{dh} = \\frac{dF}{dC} \\cdot \\frac{dC}{dh} = 1.8 \\times (-6) = -10.8 \\text{ ¬∞F/km}\n",
    "$$\n",
    "\n",
    "Each intermediate variable **multiplies** its effect through the chain.\n",
    "\n",
    "### ‚úèÔ∏è Exercise 2.1: Chain Rule Practice\n",
    "\n",
    "Compute $\\frac{dy}{dx}$ for each composition:\n",
    "\n",
    "**a)** $y = (3x + 1)^2$\n",
    "\n",
    "Hint: let $u = 3x + 1$, so $y = u^2$\n",
    "\n",
    "$\\frac{dy}{dx} =$ ___\n",
    "\n",
    "**b)** $y = \\text{sigmoid}(2x - 1)$\n",
    "\n",
    "Hint: recall $\\frac{d\\sigma}{dz} = \\sigma(z)(1 - \\sigma(z))$\n",
    "\n",
    "$\\frac{dy}{dx} =$ ___\n",
    "\n",
    "**c)** $y = (5 - \\sigma(x))^2$ (this is like a loss function!)\n",
    "\n",
    "$\\frac{dy}{dx} =$ ___\n",
    "\n",
    "<details>\n",
    "<summary>Solutions</summary>\n",
    "\n",
    "**a)** Let $u = 3x + 1$:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx} = 2u \\cdot 3 = 6(3x + 1)\n",
    "$$\n",
    "\n",
    "**b)** Let $z = 2x - 1$:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{d\\sigma}{dz} \\cdot \\frac{dz}{dx} = \\sigma(z)(1 - \\sigma(z)) \\cdot 2\n",
    "$$\n",
    "\n",
    "**c)** Let $a = \\sigma(x)$, then $y = (5 - a)^2$:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{da} \\cdot \\frac{da}{dx} = -2(5 - \\sigma(x)) \\cdot \\sigma(x)(1 - \\sigma(x))\n",
    "$$\n",
    "\n",
    "This is exactly the kind of calculation backpropagation does!\n",
    "</details>\n",
    "\n",
    "### The Chain Rule with Multiple Variables\n",
    "\n",
    "In neural networks, each weight affects the loss through a **path** of intermediate variables. The chain rule extends:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}\n",
    "$$\n",
    "\n",
    "For a longer path (deeper network):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial h} \\cdot \\frac{\\partial h}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_1}\n",
    "$$\n",
    "\n",
    "**Key insight:** Each layer contributes one **multiplication factor** in the chain.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Computational Graphs: Visualizing the Chain Rule {#comp-graphs}\n",
    "\n",
    "### What is a Computational Graph?\n",
    "\n",
    "A computational graph breaks a complex function into simple steps, showing how data flows forward and gradients flow backward.\n",
    "\n",
    "### Example: Single Neuron\n",
    "\n",
    "For $L = (\\hat{y} - y)^2$ where $\\hat{y} = \\sigma(wx + b)$:\n",
    "\n",
    "```\n",
    "Forward pass (left to right):\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "   x ‚îÄ‚îÄ‚îê\n",
    "       ‚îú‚îÄ‚îÄ [√ó] ‚îÄ‚îÄ z‚ÇÅ ‚îÄ‚îÄ‚îê\n",
    "   w ‚îÄ‚îÄ‚îò                ‚îú‚îÄ‚îÄ [+] ‚îÄ‚îÄ z ‚îÄ‚îÄ [œÉ] ‚îÄ‚îÄ ≈∑ ‚îÄ‚îÄ [-] ‚îÄ‚îÄ e ‚îÄ‚îÄ [¬≤] ‚îÄ‚îÄ L\n",
    "                   b ‚îÄ‚îÄ‚îò                        y ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "```\n",
    "Backward pass (right to left):\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "  ‚àÇL    ‚àÇL   ‚àÇL     ‚àÇL      ‚àÇL     ‚àÇL     ‚àÇL\n",
    "  ‚îÄ‚îÄ ‚Üê ‚îÄ‚îÄ ‚Üê ‚îÄ‚îÄ ‚Üê  ‚îÄ‚îÄ ‚Üê   ‚îÄ‚îÄ ‚Üê   ‚îÄ‚îÄ ‚Üê   ‚îÄ‚îÄ = 1\n",
    "  ‚àÇw   ‚àÇz‚ÇÅ  ‚àÇz    ‚àÇ≈∑      ‚àÇe     ‚àÇL     ‚àÇL\n",
    "```\n",
    "\n",
    "### Reading the Graph\n",
    "\n",
    "**Forward pass** (compute the output):\n",
    "1. $z_1 = w \\cdot x$\n",
    "2. $z = z_1 + b$\n",
    "3. $\\hat{y} = \\sigma(z)$\n",
    "4. $e = \\hat{y} - y$\n",
    "5. $L = e^2$\n",
    "\n",
    "**Backward pass** (compute the gradients):\n",
    "1. $\\frac{\\partial L}{\\partial L} = 1$ (starting point)\n",
    "2. $\\frac{\\partial L}{\\partial e} = 2e$\n",
    "3. $\\frac{\\partial L}{\\partial \\hat{y}} = \\frac{\\partial L}{\\partial e} \\cdot 1 = 2e$\n",
    "4. $\\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\sigma'(z) = 2e \\cdot \\sigma(z)(1-\\sigma(z))$\n",
    "5. $\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial z} \\cdot x$\n",
    "6. $\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial z} \\cdot 1$\n",
    "\n",
    "### ü§î Think About It\n",
    "\n",
    "**Q:** Notice that $\\frac{\\partial L}{\\partial z}$ is used to compute **both** $\\frac{\\partial L}{\\partial w}$ and $\\frac{\\partial L}{\\partial b}$. Why is this efficient?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Because $w$ and $b$ both feed into the same node $z$. Once we know how the loss changes with respect to $z$, we can quickly find how it changes with respect to anything that contributes to $z$. This **reuse of intermediate gradients** is what makes backpropagation efficient ‚Äî we compute each intermediate gradient only once!\n",
    "</details>\n",
    "\n",
    "### ‚úèÔ∏è Exercise 3.1: Trace the Backward Pass\n",
    "\n",
    "Given: $x = 2$, $w = 0.5$, $b = -0.5$, $y = 1$\n",
    "\n",
    "**Forward pass** (fill in the values):\n",
    "\n",
    "| Step | Computation | Value |\n",
    "|------|------------|-------|\n",
    "| 1    | $z_1 = wx$ | ___ |\n",
    "| 2    | $z = z_1 + b$ | ___ |\n",
    "| 3    | $\\hat{y} = \\sigma(z)$ | ___ |\n",
    "| 4    | $e = \\hat{y} - y$ | ___ |\n",
    "| 5    | $L = e^2$ | ___ |\n",
    "\n",
    "**Backward pass** (fill in the gradients):\n",
    "\n",
    "| Step | Gradient | Value |\n",
    "|------|----------|-------|\n",
    "| 1    | $\\frac{\\partial L}{\\partial e} = 2e$ | ___ |\n",
    "| 2    | $\\frac{\\partial L}{\\partial \\hat{y}} = \\frac{\\partial L}{\\partial e} \\cdot 1$ | ___ |\n",
    "| 3    | $\\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\sigma(z)(1 - \\sigma(z))$ | ___ |\n",
    "| 4    | $\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial z} \\cdot x$ | ___ |\n",
    "| 5    | $\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial z} \\cdot 1$ | ___ |\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Forward pass:**\n",
    "\n",
    "| Step | Computation | Value |\n",
    "|------|------------|-------|\n",
    "| 1    | $z_1 = 0.5 \\times 2$ | $1.0$ |\n",
    "| 2    | $z = 1.0 + (-0.5)$ | $0.5$ |\n",
    "| 3    | $\\hat{y} = \\sigma(0.5) = \\frac{1}{1+e^{-0.5}}$ | $\\approx 0.6225$ |\n",
    "| 4    | $e = 0.6225 - 1$ | $\\approx -0.3775$ |\n",
    "| 5    | $L = (-0.3775)^2$ | $\\approx 0.1425$ |\n",
    "\n",
    "**Backward pass:**\n",
    "\n",
    "| Step | Gradient | Value |\n",
    "|------|----------|-------|\n",
    "| 1    | $\\frac{\\partial L}{\\partial e} = 2(-0.3775)$ | $\\approx -0.7550$ |\n",
    "| 2    | $\\frac{\\partial L}{\\partial \\hat{y}} = -0.7550$ | $\\approx -0.7550$ |\n",
    "| 3    | $\\frac{\\partial L}{\\partial z} = -0.7550 \\times 0.6225 \\times (1 - 0.6225)$ | $\\approx -0.1774$ |\n",
    "| 4    | $\\frac{\\partial L}{\\partial w} = -0.1774 \\times 2$ | $\\approx -0.3549$ |\n",
    "| 5    | $\\frac{\\partial L}{\\partial b} = -0.1774 \\times 1$ | $\\approx -0.1774$ |\n",
    "\n",
    "Both gradients are **negative** ‚Üí the loss decreases when we increase $w$ and $b$ ‚Üí gradient descent will increase both.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Backpropagation: The Algorithm {#backprop}\n",
    "\n",
    "### Overview\n",
    "\n",
    "Backpropagation = **\"backward propagation of errors\"**\n",
    "\n",
    "It is not a new concept ‚Äî it's just the chain rule applied systematically through a network. But the key insight is **how** we organize the computation:\n",
    "\n",
    "1. **Forward pass**: Compute and **store** all intermediate values\n",
    "2. **Backward pass**: Compute gradients from output to input, **reusing** stored values\n",
    "\n",
    "### The General Setup\n",
    "\n",
    "For a network with $L$ layers:\n",
    "\n",
    "**Forward pass** ‚Äî for each layer $l = 1, 2, \\ldots, L$:\n",
    "\n",
    "$$\n",
    "z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}\n",
    "$$\n",
    "$$\n",
    "a^{(l)} = f^{(l)}(z^{(l)})\n",
    "$$\n",
    "\n",
    "Where $a^{(0)} = \\mathbf{x}$ (the input) and $f^{(l)}$ is the activation function for layer $l$.\n",
    "\n",
    "**Loss computation:**\n",
    "\n",
    "$$\n",
    "L = \\text{MSE}(y, a^{(L)}) = (y - a^{(L)})^2\n",
    "$$\n",
    "\n",
    "### The Key Quantity: $\\delta^{(l)}$\n",
    "\n",
    "We define the **error signal** for layer $l$:\n",
    "\n",
    "$$\n",
    "\\delta^{(l)} = \\frac{\\partial L}{\\partial z^{(l)}}\n",
    "$$\n",
    "\n",
    "This tells us: \"How does the loss change when we change the weighted sum at layer $l$?\"\n",
    "\n",
    "Once we have $\\delta^{(l)}$, the gradients for that layer are easy:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W^{(l)}} = \\delta^{(l)} \\cdot (a^{(l-1)})^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b^{(l)}} = \\delta^{(l)}\n",
    "$$\n",
    "\n",
    "### Backward Pass ‚Äî Computing $\\delta$\n",
    "\n",
    "**Output layer** (layer $L$):\n",
    "\n",
    "$$\n",
    "\\delta^{(L)} = \\frac{\\partial L}{\\partial a^{(L)}} \\odot f'^{(L)}(z^{(L)})\n",
    "$$\n",
    "\n",
    "For MSE loss: $\\frac{\\partial L}{\\partial a^{(L)}} = -2(y - a^{(L)})$\n",
    "\n",
    "**Hidden layers** (layer $l < L$) ‚Äî the magic formula:\n",
    "\n",
    "$$\n",
    "\\delta^{(l)} = \\left( (W^{(l+1)})^T \\delta^{(l+1)} \\right) \\odot f'^{(l)}(z^{(l)})\n",
    "$$\n",
    "\n",
    "**In words:** The error signal at layer $l$ =  \n",
    "(error signal from the next layer, **pulled back** through the weights) √ó (slope of the activation function)\n",
    "\n",
    "The symbol $\\odot$ means element-wise multiplication.\n",
    "\n",
    "### ü§î Think About It\n",
    "\n",
    "**Q:** Why do we multiply by the **transpose** of $W^{(l+1)}$?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "In the forward pass, $W^{(l+1)}$ maps activations **forward** (from layer $l$ to $l+1$). In the backward pass, we need to map errors **backward** (from layer $l+1$ to $l$). The transpose does exactly this ‚Äî it \"reverses\" the connections, distributing each output error back to the hidden neurons that contributed to it.\n",
    "</details>\n",
    "\n",
    "### The Complete Algorithm\n",
    "\n",
    "```\n",
    "BACKPROPAGATION ALGORITHM\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "Input: training sample (x, y), network parameters {W, b}\n",
    "\n",
    "FORWARD PASS:\n",
    "  a‚ÅΩ‚Å∞‚Åæ = x\n",
    "  for l = 1 to L:\n",
    "      z‚ÅΩÀ°‚Åæ = W‚ÅΩÀ°‚Åæ a‚ÅΩÀ°‚Åª¬π‚Åæ + b‚ÅΩÀ°‚Åæ\n",
    "      a‚ÅΩÀ°‚Åæ = f(z‚ÅΩÀ°‚Åæ)\n",
    "      STORE z‚ÅΩÀ°‚Åæ and a‚ÅΩÀ°‚Åæ        ‚Üê Important!\n",
    "\n",
    "LOSS:\n",
    "  L = loss(y, a‚ÅΩ·¥∏‚Åæ)\n",
    "\n",
    "BACKWARD PASS:\n",
    "  Œ¥‚ÅΩ·¥∏‚Åæ = ‚àÇL/‚àÇa‚ÅΩ·¥∏‚Åæ ‚äô f'(z‚ÅΩ·¥∏‚Åæ)    ‚Üê output layer error\n",
    "  for l = L-1 down to 1:\n",
    "      Œ¥‚ÅΩÀ°‚Åæ = (W‚ÅΩÀ°‚Å∫¬π‚Åæ)·µÄ Œ¥‚ÅΩÀ°‚Å∫¬π‚Åæ ‚äô f'(z‚ÅΩÀ°‚Åæ)   ‚Üê propagate backward\n",
    "\n",
    "GRADIENTS:\n",
    "  for l = 1 to L:\n",
    "      ‚àÇL/‚àÇW‚ÅΩÀ°‚Åæ = Œ¥‚ÅΩÀ°‚Åæ (a‚ÅΩÀ°‚Åª¬π‚Åæ)·µÄ\n",
    "      ‚àÇL/‚àÇb‚ÅΩÀ°‚Åæ = Œ¥‚ÅΩÀ°‚Åæ\n",
    "\n",
    "UPDATE:\n",
    "  for l = 1 to L:\n",
    "      W‚ÅΩÀ°‚Åæ ‚Üê W‚ÅΩÀ°‚Åæ - Œ∑ ‚àÇL/‚àÇW‚ÅΩÀ°‚Åæ\n",
    "      b‚ÅΩÀ°‚Åæ ‚Üê b‚ÅΩÀ°‚Åæ - Œ∑ ‚àÇL/‚àÇb‚ÅΩÀ°‚Åæ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Step-by-Step: Backprop on a 2-2-1 Network {#step-by-step}\n",
    "\n",
    "### Network Setup\n",
    "\n",
    "Let's trace backpropagation through our familiar XOR network architecture:\n",
    "\n",
    "```\n",
    "Input (2)    Hidden (2)    Output (1)\n",
    "  x‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ h‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "       ‚ï≤  ‚ï±             ‚îú‚îÄ‚îÄ ≈∑\n",
    "       ‚ï±  ‚ï≤             ‚îÇ\n",
    "  x‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ h‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- $W^{(1)} \\in \\mathbb{R}^{2 \\times 2}$, $b^{(1)} \\in \\mathbb{R}^{2}$ (input ‚Üí hidden)\n",
    "- $W^{(2)} \\in \\mathbb{R}^{1 \\times 2}$, $b^{(2)} \\in \\mathbb{R}^{1}$ (hidden ‚Üí output)\n",
    "- Activation: sigmoid everywhere\n",
    "- Loss: MSE\n",
    "\n",
    "### Concrete Example\n",
    "\n",
    "**Given:**\n",
    "\n",
    "$$\n",
    "W^{(1)} = \\begin{bmatrix} 0.5 & 0.3 \\\\ -0.2 & 0.8 \\end{bmatrix}, \\quad b^{(1)} = \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W^{(2)} = \\begin{bmatrix} 0.6 & -0.4 \\end{bmatrix}, \\quad b^{(2)} = 0.2\n",
    "$$\n",
    "\n",
    "**Input:** $x = [1, 0]^T$, **Target:** $y = 1$\n",
    "\n",
    "### Step 1: Forward Pass\n",
    "\n",
    "**Hidden layer:**\n",
    "\n",
    "$$\n",
    "z^{(1)} = W^{(1)} x + b^{(1)} = \\begin{bmatrix} 0.5 & 0.3 \\\\ -0.2 & 0.8 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 0.5 + 0.1 \\\\ -0.2 - 0.1 \\end{bmatrix} = \\begin{bmatrix} 0.6 \\\\ -0.3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{(1)} = \\sigma(z^{(1)}) = \\begin{bmatrix} \\sigma(0.6) \\\\ \\sigma(-0.3) \\end{bmatrix} \\approx \\begin{bmatrix} 0.6457 \\\\ 0.4256 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Output layer:**\n",
    "\n",
    "$$\n",
    "z^{(2)} = W^{(2)} a^{(1)} + b^{(2)} = \\begin{bmatrix} 0.6 & -0.4 \\end{bmatrix} \\begin{bmatrix} 0.6457 \\\\ 0.4256 \\end{bmatrix} + 0.2\n",
    "$$\n",
    "\n",
    "$$\n",
    "z^{(2)} = 0.6 \\times 0.6457 + (-0.4) \\times 0.4256 + 0.2 = 0.3874 - 0.1702 + 0.2 = 0.4172\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = a^{(2)} = \\sigma(0.4172) \\approx 0.6028\n",
    "$$\n",
    "\n",
    "**Loss:**\n",
    "\n",
    "$$\n",
    "L = (y - \\hat{y})^2 = (1 - 0.6028)^2 = (0.3972)^2 \\approx 0.1578\n",
    "$$\n",
    "\n",
    "### Step 2: Backward Pass ‚Äî Output Layer\n",
    "\n",
    "We need $\\delta^{(2)}$:\n",
    "\n",
    "$$\n",
    "\\delta^{(2)} = \\frac{\\partial L}{\\partial z^{(2)}} = \\frac{\\partial L}{\\partial a^{(2)}} \\cdot \\sigma'(z^{(2)})\n",
    "$$\n",
    "\n",
    "**Loss gradient:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a^{(2)}} = -2(y - \\hat{y}) = -2(1 - 0.6028) = -0.7944\n",
    "$$\n",
    "\n",
    "**Sigmoid derivative:** $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z)) = 0.6028 \\times 0.3972 = 0.2395$\n",
    "\n",
    "$$\n",
    "\\delta^{(2)} = -0.7944 \\times 0.2395 \\approx -0.1903\n",
    "$$\n",
    "\n",
    "### ‚úèÔ∏è Exercise 5.1: Compute Output Layer Gradients\n",
    "\n",
    "Using $\\delta^{(2)} = -0.1903$ and $a^{(1)} = [0.6457, 0.4256]^T$:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^{(2)}} = \\delta^{(2)} \\cdot (a^{(1)})^T =$ ___\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b^{(2)}} = \\delta^{(2)} =$ ___\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W^{(2)}} = -0.1903 \\times \\begin{bmatrix} 0.6457 & 0.4256 \\end{bmatrix} = \\begin{bmatrix} -0.1229 & -0.0810 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b^{(2)}} = -0.1903\n",
    "$$\n",
    "\n",
    "Both gradients are **negative** ‚Üí gradient descent will **increase** these values ‚Üí pushing the output closer to 1 ‚úì\n",
    "</details>\n",
    "\n",
    "### Step 3: Backward Pass ‚Äî Hidden Layer\n",
    "\n",
    "Now the magic: propagating the error **backward** to the hidden layer.\n",
    "\n",
    "$$\n",
    "\\delta^{(1)} = \\left( (W^{(2)})^T \\delta^{(2)} \\right) \\odot \\sigma'(z^{(1)})\n",
    "$$\n",
    "\n",
    "**Pull error back through weights:**\n",
    "\n",
    "$$\n",
    "(W^{(2)})^T \\delta^{(2)} = \\begin{bmatrix} 0.6 \\\\ -0.4 \\end{bmatrix} \\times (-0.1903) = \\begin{bmatrix} -0.1142 \\\\ 0.0761 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Multiply by sigmoid derivative:**\n",
    "\n",
    "$$\n",
    "\\sigma'(z^{(1)}) = \\begin{bmatrix} \\sigma(0.6)(1 - \\sigma(0.6)) \\\\ \\sigma(-0.3)(1 - \\sigma(-0.3)) \\end{bmatrix} = \\begin{bmatrix} 0.6457 \\times 0.3543 \\\\ 0.4256 \\times 0.5744 \\end{bmatrix} \\approx \\begin{bmatrix} 0.2288 \\\\ 0.2445 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta^{(1)} = \\begin{bmatrix} -0.1142 \\\\ 0.0761 \\end{bmatrix} \\odot \\begin{bmatrix} 0.2288 \\\\ 0.2445 \\end{bmatrix} = \\begin{bmatrix} -0.0261 \\\\ 0.0186 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### ‚úèÔ∏è Exercise 5.2: Compute Hidden Layer Gradients\n",
    "\n",
    "Using $\\delta^{(1)} = [-0.0261, 0.0186]^T$ and $a^{(0)} = x = [1, 0]^T$:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^{(1)}} = \\delta^{(1)} \\cdot (a^{(0)})^T =$ ___\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b^{(1)}} = \\delta^{(1)} =$ ___\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W^{(1)}} = \\begin{bmatrix} -0.0261 \\\\ 0.0186 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\end{bmatrix} = \\begin{bmatrix} -0.0261 & 0 \\\\ 0.0186 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b^{(1)}} = \\begin{bmatrix} -0.0261 \\\\ 0.0186 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note: the second column of $\\frac{\\partial L}{\\partial W^{(1)}}$ is zero because $x_2 = 0$ ‚Äî a weight has no gradient contribution from an input that is zero!\n",
    "</details>\n",
    "\n",
    "### Step 4: Update All Weights\n",
    "\n",
    "With learning rate $\\eta = 1.0$ (large for demonstration):\n",
    "\n",
    "$$\n",
    "W^{(2)}_{\\text{new}} = W^{(2)} - \\eta \\frac{\\partial L}{\\partial W^{(2)}} = \\begin{bmatrix} 0.6 & -0.4 \\end{bmatrix} - 1.0 \\times \\begin{bmatrix} -0.1229 & -0.0810 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix} 0.7229 & -0.3190 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Interpretation:** $w_{21}$ increased (stronger connection from h‚ÇÅ) and $w_{22}$ increased (weaker negative connection from h‚ÇÇ), both pushing the output closer to 1.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Implementing Backpropagation from Scratch {#implementation}\n",
    "\n",
    "### Activation Functions and Their Derivatives\n",
    "\n",
    "Before implementing backprop, we need the sigmoid derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c41eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    \"\"\"Derivative of sigmoid: œÉ(z)(1 - œÉ(z))\"\"\"\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4527727",
   "metadata": {},
   "source": [
    "### ü§î Quick Check\n",
    "\n",
    "**Q:** What is the maximum value of $\\sigma'(z)$? At what value of $z$?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "The maximum is $\\sigma'(0) = 0.5 \\times 0.5 = 0.25$, occurring at $z = 0$.\n",
    "\n",
    "This means the sigmoid \"passes through\" at most **25%** of the gradient at each layer. For deep networks, this causes the **vanishing gradient problem** ‚Äî gradients shrink exponentially as they propagate backward through many sigmoid layers. This is one reason ReLU became popular (its derivative is either 0 or 1).\n",
    "</details>\n",
    "\n",
    "### The MLP Class\n",
    "\n",
    "**Fill in the blanks for the backward pass:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    A 2-layer MLP (input ‚Üí hidden ‚Üí output) trained with backpropagation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        \"\"\"Initialize with random weights\"\"\"\n",
    "        np.random.seed(42)\n",
    "        # Xavier initialization (better than pure random)\n",
    "        self.W1 = np.random.randn(n_hidden, n_input) * np.sqrt(2.0 / n_input)\n",
    "        self.b1 = np.zeros((n_hidden, 1))\n",
    "        self.W2 = np.random.randn(n_output, n_hidden) * np.sqrt(2.0 / n_hidden)\n",
    "        self.b2 = np.zeros((n_output, 1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass. X shape: (n_input, N) where N = number of samples.\n",
    "        \n",
    "        IMPORTANT: Store intermediate values for backprop!\n",
    "        \"\"\"\n",
    "        # Hidden layer\n",
    "        self.z1 = self.W1 @ X + self.b1          # (n_hidden, N)\n",
    "        self.a1 = sigmoid(self.z1)                # (n_hidden, N)\n",
    "        \n",
    "        # Output layer\n",
    "        self.z2 = self.W2 @ self.a1 + self.b2    # (n_output, N)\n",
    "        self.a2 = sigmoid(self.z2)                # (n_output, N)\n",
    "        \n",
    "        return self.a2\n",
    "    \n",
    "    def compute_loss(self, y_true):\n",
    "        \"\"\"MSE loss\"\"\"\n",
    "        N = y_true.shape[1]\n",
    "        return np.mean((y_true - self.a2) ** 2)\n",
    "    \n",
    "    def backward(self, X, y_true, lr):\n",
    "        \"\"\"\n",
    "        Backward pass + weight update.\n",
    "        \n",
    "        X shape: (n_input, N)\n",
    "        y_true shape: (n_output, N)\n",
    "        \"\"\"\n",
    "        N = X.shape[1]  # Number of samples\n",
    "        \n",
    "        # --- Output layer gradients ---\n",
    "        \n",
    "        # dL/da2 = -2(y - a2) / N\n",
    "        dL_da2 = -2 * (y_true - self.a2) / N\n",
    "        \n",
    "        # delta2 = dL/dz2 = dL/da2 * sigmoid'(z2)\n",
    "        delta2 = dL_da2 * sigmoid_derivative(self.z2)     # (n_output, N)\n",
    "        \n",
    "        # Gradients for W2 and b2\n",
    "        dW2 = delta2 @ self.a1.T                           # (n_output, n_hidden)\n",
    "        db2 = np.sum(delta2, axis=1, keepdims=True)        # (n_output, 1)\n",
    "        \n",
    "        # --- Hidden layer gradients ---\n",
    "        \n",
    "        # TODO: Propagate error backward through W2\n",
    "        delta1 = (___.T @ ___) * sigmoid_derivative(___)   # Fill in!\n",
    "        \n",
    "        # TODO: Gradients for W1 and b1\n",
    "        dW1 = ___ @ ___.T                                  # Fill in!\n",
    "        db1 = np.sum(___, axis=1, keepdims=True)            # Fill in!\n",
    "        \n",
    "        # --- Update weights ---\n",
    "        self.W2 -= lr * dW2\n",
    "        self.b2 -= lr * db2\n",
    "        self.W1 -= lr * dW1\n",
    "        self.b1 -= lr * db1\n",
    "        \n",
    "        return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73e82f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution for blanks</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee275e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate error backward through W2\n",
    "delta1 = (self.W2.T @ delta2) * sigmoid_derivative(self.z1)\n",
    "\n",
    "# Gradients for W1 and b1\n",
    "dW1 = delta1 @ X.T\n",
    "db1 = np.sum(delta1, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce810b7",
   "metadata": {},
   "source": [
    "**Why these formulas?**\n",
    "\n",
    "- `self.W2.T @ delta2`: pulls the output error back through the weights (transpose reverses the direction)\n",
    "- `* sigmoid_derivative(self.z1)`: scales by how much each hidden neuron's activation changes\n",
    "- `delta1 @ X.T`: the gradient for $W^{(1)}$ is the error signal times the input (just like in linear regression!)\n",
    "</details>\n",
    "\n",
    "### üíª Code It: Verify the Shapes\n",
    "\n",
    "Understanding matrix dimensions is crucial for debugging. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62647af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small network: 2 inputs, 3 hidden, 1 output\n",
    "mlp = MLP(n_input=2, n_hidden=3, n_output=1)\n",
    "\n",
    "# Dummy data: 4 samples\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]], dtype=float)  # (2, 4)\n",
    "y = np.array([[0, 1, 1, 0]], dtype=float)   # (1, 4) ‚Äî XOR!\n",
    "\n",
    "# Forward pass\n",
    "output = mlp.forward(X)\n",
    "\n",
    "print(\"Shape check:\")\n",
    "print(f\"  X:     {X.shape}\")           # (2, 4)\n",
    "print(f\"  W1:    {mlp.W1.shape}\")      # (3, 2)\n",
    "print(f\"  z1:    {mlp.z1.shape}\")      # (3, 4)\n",
    "print(f\"  a1:    {mlp.a1.shape}\")      # (3, 4)\n",
    "print(f\"  W2:    {mlp.W2.shape}\")      # (1, 3)\n",
    "print(f\"  z2:    {mlp.z2.shape}\")      # (1, 4)\n",
    "print(f\"  a2:    {mlp.a2.shape}\")      # (1, 4)\n",
    "print(f\"  y:     {y.shape}\")           # (1, 4)\n",
    "print(f\"  output: {output.shape}\")     # (1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3280a",
   "metadata": {},
   "source": [
    "### Shape Rule of Thumb\n",
    "\n",
    "| Quantity | Shape | Why |\n",
    "|---|---|---|\n",
    "| $W^{(l)}$ | (neurons in $l$, neurons in $l{-}1$) | Maps from layer $l{-}1$ to $l$ |\n",
    "| $b^{(l)}$ | (neurons in $l$, 1) | One bias per neuron |\n",
    "| $z^{(l)}, a^{(l)}$ | (neurons in $l$, $N$) | One column per sample |\n",
    "| $\\delta^{(l)}$ | (neurons in $l$, $N$) | Same shape as $z^{(l)}$ |\n",
    "| $\\frac{\\partial L}{\\partial W^{(l)}}$ | Same as $W^{(l)}$ | One gradient per weight |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Training the XOR Network (Finally!) {#xor-training}\n",
    "\n",
    "### The Moment We've Been Waiting For\n",
    "\n",
    "Since Session 4, we've been trying to solve XOR. We built the network, did forward propagation, and tried manual weight tuning. Now we can **train it automatically**!\n",
    "\n",
    "### üíª Code It: Train on XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daad478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# XOR dataset\n",
    "X_xor = np.array([[0, 0, 1, 1],\n",
    "                   [0, 1, 0, 1]], dtype=float)\n",
    "y_xor = np.array([[0, 1, 1, 0]], dtype=float)\n",
    "\n",
    "# Create network: 2 inputs, 4 hidden neurons, 1 output\n",
    "mlp = MLP(n_input=2, n_hidden=4, n_output=1)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10000\n",
    "lr = 2.0  # Sigmoid networks often need larger learning rates\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    output = mlp.forward(X_xor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = mlp.compute_loss(y_xor)\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    # Backward pass + update\n",
    "    mlp.backward(X_xor, y_xor, lr)\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 2000 == 0:\n",
    "        predictions = (output > 0.5).astype(int)\n",
    "        accuracy = np.mean(predictions == y_xor) * 100\n",
    "        print(f\"Epoch {epoch:5d}: Loss = {loss:.6f}, Accuracy = {accuracy:.0f}%\")\n",
    "\n",
    "# Final results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "output = mlp.forward(X_xor)\n",
    "for i in range(4):\n",
    "    x1, x2 = X_xor[0, i], X_xor[1, i]\n",
    "    pred = output[0, i]\n",
    "    true = y_xor[0, i]\n",
    "    status = \"‚úì\" if (pred > 0.5) == true else \"‚úó\"\n",
    "    print(f\"{status} Input: ({x1:.0f}, {x2:.0f}) ‚Üí Output: {pred:.4f} ‚Üí \"\n",
    "          f\"Predicted: {int(pred > 0.5)} (True: {int(true)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed1ddc",
   "metadata": {},
   "source": [
    "### üíª Code It: Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Loss curve\n",
    "ax = axes[0]\n",
    "ax.plot(loss_history, 'b-', linewidth=1)\n",
    "ax.set_xlabel('Epoch', fontsize=14)\n",
    "ax.set_ylabel('MSE Loss', fontsize=14)\n",
    "ax.set_title('XOR Training: Loss Over Time', fontsize=16)\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Decision boundary\n",
    "ax = axes[1]\n",
    "x_range = np.linspace(-0.5, 1.5, 200)\n",
    "y_range = np.linspace(-0.5, 1.5, 200)\n",
    "X_grid, Y_grid = np.meshgrid(x_range, y_range)\n",
    "grid_input = np.vstack([X_grid.ravel(), Y_grid.ravel()])  # (2, 40000)\n",
    "\n",
    "Z_grid = mlp.forward(grid_input).reshape(X_grid.shape)\n",
    "\n",
    "ax.contourf(X_grid, Y_grid, Z_grid, levels=[0, 0.5, 1], \n",
    "            colors=['#ADD8E6', '#FFCCCB'], alpha=0.5)\n",
    "ax.contour(X_grid, Y_grid, Z_grid, levels=[0.5], colors='black', linewidths=2)\n",
    "\n",
    "# Plot XOR points\n",
    "ax.scatter([0, 1], [0, 1], s=300, c='blue', marker='o', \n",
    "           edgecolors='black', linewidth=3, label='Class 0', zorder=5)\n",
    "ax.scatter([0, 1], [1, 0], s=300, c='red', marker='s', \n",
    "           edgecolors='black', linewidth=3, label='Class 1', zorder=5)\n",
    "\n",
    "ax.set_xlabel('$x_1$', fontsize=14)\n",
    "ax.set_ylabel('$x_2$', fontsize=14)\n",
    "ax.set_title('Learned Decision Boundary', fontsize=16)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3c28c",
   "metadata": {},
   "source": [
    "### üéâ What Just Happened?\n",
    "\n",
    "The network **learned** to solve XOR by itself! Compare:\n",
    "\n",
    "| Approach | Session | Method | Result |\n",
    "|---|---|---|---|\n",
    "| Manual weights | Session 4 | Trial and error | Found a solution (painfully) |\n",
    "| Auto-trained | Session 6 | Backprop + GD | Found a solution automatically! |\n",
    "\n",
    "The network discovered its own way to decompose XOR into sub-problems ‚Äî and it might have found a **different** solution than our manual one!\n",
    "\n",
    "### üíª Code It: What Did the Hidden Neurons Learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ad6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hidden_neurons(mlp):\n",
    "    \"\"\"Visualize what each hidden neuron responds to\"\"\"\n",
    "    x_range = np.linspace(-0.5, 1.5, 200)\n",
    "    y_range = np.linspace(-0.5, 1.5, 200)\n",
    "    X_grid, Y_grid = np.meshgrid(x_range, y_range)\n",
    "    grid_input = np.vstack([X_grid.ravel(), Y_grid.ravel()])\n",
    "    \n",
    "    # Get hidden activations\n",
    "    z1 = mlp.W1 @ grid_input + mlp.b1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    n_hidden = a1.shape[0]\n",
    "    fig, axes = plt.subplots(1, n_hidden, figsize=(5 * n_hidden, 4))\n",
    "    if n_hidden == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx in range(n_hidden):\n",
    "        ax = axes[idx]\n",
    "        Z = a1[idx].reshape(X_grid.shape)\n",
    "        \n",
    "        contour = ax.contourf(X_grid, Y_grid, Z, levels=20, cmap='RdYlBu_r')\n",
    "        plt.colorbar(contour, ax=ax)\n",
    "        \n",
    "        ax.scatter([0, 1], [0, 1], s=150, c='blue', marker='o', \n",
    "                   edgecolors='black', linewidth=2)\n",
    "        ax.scatter([0, 1], [1, 0], s=150, c='red', marker='s', \n",
    "                   edgecolors='black', linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('$x_1$', fontsize=11)\n",
    "        ax.set_ylabel('$x_2$', fontsize=11)\n",
    "        ax.set_title(f'Hidden Neuron h{idx+1}', fontsize=13)\n",
    "        ax.set_xlim(-0.5, 1.5)\n",
    "        ax.set_ylim(-0.5, 1.5)\n",
    "    \n",
    "    plt.suptitle('What Each Hidden Neuron Learned', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_hidden_neurons(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359aeedc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Gradient Checking: Verifying Your Gradients {#grad-check}\n",
    "\n",
    "### Why Gradient Checking?\n",
    "\n",
    "Backpropagation involves a lot of matrix operations. It's easy to make mistakes (wrong transpose, missing factor of 2, etc.). **Gradient checking** compares your analytical gradients to numerical approximations.\n",
    "\n",
    "### The Method\n",
    "\n",
    "For each weight $w_{ij}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{ij}} \\approx \\frac{L(w_{ij} + \\epsilon) - L(w_{ij} - \\epsilon)}{2\\epsilon}\n",
    "$$\n",
    "\n",
    "If the analytical and numerical gradients agree (relative difference < $10^{-5}$), your implementation is likely correct!\n",
    "\n",
    "### üíª Code It: Gradient Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(mlp, X, y, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Verify backprop gradients against numerical gradients.\n",
    "    \n",
    "    Returns the maximum relative error.\n",
    "    \"\"\"\n",
    "    # Get analytical gradients from backprop\n",
    "    mlp.forward(X)\n",
    "    dW1, db1, dW2, db2 = mlp.backward(X, y, lr=0.0)  # lr=0 so weights don't change\n",
    "    \n",
    "    max_error = 0\n",
    "    \n",
    "    # Check each parameter set\n",
    "    for name, param, grad in [('W1', mlp.W1, dW1), ('b1', mlp.b1, db1),\n",
    "                               ('W2', mlp.W2, dW2), ('b2', mlp.b2, db2)]:\n",
    "        print(f\"\\nChecking {name} (shape {param.shape}):\")\n",
    "        \n",
    "        # Numerical gradient for each element\n",
    "        num_grad = np.zeros_like(param)\n",
    "        \n",
    "        for idx in np.ndindex(param.shape):\n",
    "            # Save original\n",
    "            original = param[idx]\n",
    "            \n",
    "            # L(w + Œµ)\n",
    "            param[idx] = original + epsilon\n",
    "            mlp.forward(X)\n",
    "            loss_plus = mlp.compute_loss(y)\n",
    "            \n",
    "            # L(w - Œµ)\n",
    "            param[idx] = original - epsilon\n",
    "            mlp.forward(X)\n",
    "            loss_minus = mlp.compute_loss(y)\n",
    "            \n",
    "            # Numerical gradient\n",
    "            num_grad[idx] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "            \n",
    "            # Restore\n",
    "            param[idx] = original\n",
    "        \n",
    "        # Compare\n",
    "        diff = np.abs(grad - num_grad)\n",
    "        denom = np.maximum(np.abs(grad) + np.abs(num_grad), 1e-8)\n",
    "        relative_error = np.max(diff / denom)\n",
    "        max_error = max(max_error, relative_error)\n",
    "        \n",
    "        print(f\"  Max absolute diff:  {np.max(diff):.2e}\")\n",
    "        print(f\"  Max relative error: {relative_error:.2e}\")\n",
    "        \n",
    "        if relative_error < 1e-5:\n",
    "            print(f\"  ‚úì PASSED\")\n",
    "        else:\n",
    "            print(f\"  ‚úó FAILED ‚Äî check your backprop implementation!\")\n",
    "    \n",
    "    return max_error\n",
    "\n",
    "# Run gradient check\n",
    "mlp_check = MLP(n_input=2, n_hidden=3, n_output=1)\n",
    "X_check = np.array([[1.0], [0.5]])\n",
    "y_check = np.array([[1.0]])\n",
    "\n",
    "max_err = gradient_check(mlp_check, X_check, y_check)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Overall max relative error: {max_err:.2e}\")\n",
    "if max_err < 1e-5:\n",
    "    print(\"‚úì All gradients verified!\")\n",
    "else:\n",
    "    print(\"‚úó Some gradients may be incorrect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d7ed1",
   "metadata": {},
   "source": [
    "### Common Backprop Bugs That Gradient Checking Catches\n",
    "\n",
    "| Bug | Symptom |\n",
    "|---|---|\n",
    "| Missing factor of 2 in MSE gradient | Gradients are off by factor of 2 |\n",
    "| Wrong transpose on $W^T$ | Gradient shapes mismatch |\n",
    "| Forgot to divide by $N$ (batch size) | Gradients scale with batch size |\n",
    "| Used $a^{(l)}$ instead of $z^{(l)}$ in $\\sigma'$ | Gradients are wrong for non-zero inputs |\n",
    "| Didn't store $z$ during forward pass | Using stale values from previous forward pass |\n",
    "\n",
    "### ‚úèÔ∏è Exercise 8.1: Spot the Bug\n",
    "\n",
    "This backprop implementation has **one bug**. Can you find it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ecc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buggy_backward(self, X, y_true, lr):\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    dL_da2 = -2 * (y_true - self.a2) / N\n",
    "    delta2 = dL_da2 * sigmoid_derivative(self.a2)   # BUG HERE?\n",
    "    \n",
    "    dW2 = delta2 @ self.a1.T\n",
    "    db2 = np.sum(delta2, axis=1, keepdims=True)\n",
    "    \n",
    "    delta1 = (self.W2.T @ delta2) * sigmoid_derivative(self.z1)\n",
    "    \n",
    "    dW1 = delta1 @ X.T\n",
    "    db1 = np.sum(delta1, axis=1, keepdims=True)\n",
    "    \n",
    "    self.W2 -= lr * dW2\n",
    "    self.b2 -= lr * db2\n",
    "    self.W1 -= lr * dW1\n",
    "    self.b1 -= lr * db1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b70ede",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>The bug</summary>\n",
    "\n",
    "**Line 4:** `sigmoid_derivative(self.a2)` should be `sigmoid_derivative(self.z2)`.\n",
    "\n",
    "The sigmoid derivative is computed at the **weighted sum** $z$, not the **activation** $a$.\n",
    "\n",
    "This is a very common bug! Remember: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$, which is different from $\\sigma'(\\sigma(z))$.\n",
    "\n",
    "If you pass $a = \\sigma(z)$ to `sigmoid_derivative`, you'd compute $a(1-a)$ which equals $\\sigma(z)(1 - \\sigma(z))$ ‚Äî wait, that actually gives the **same result** in this case! This is a special property of sigmoid: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z)) = a(1 - a)$.\n",
    "\n",
    "So for sigmoid specifically, both work. But for other activations (like ReLU), using $a$ instead of $z$ would give **wrong results**. Always use $z$ ‚Äî it's the correct and general approach.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Final Exercises {#exercises}\n",
    "\n",
    "### üìù Exercise 9.1: Backprop by Hand (Easy)\n",
    "\n",
    "Given a tiny network with **1 input, 1 hidden neuron, 1 output** (all sigmoid):\n",
    "\n",
    "- $w_1 = 0.5$, $b_1 = 0$, $w_2 = -1.0$, $b_2 = 0.5$\n",
    "- Input: $x = 1.0$, Target: $y = 0$\n",
    "\n",
    "**Compute:**\n",
    "1. Forward pass: $z_1$, $a_1$, $z_2$, $\\hat{y}$, $L$\n",
    "2. $\\delta^{(2)}$ (output error signal)\n",
    "3. $\\frac{\\partial L}{\\partial w_2}$ and $\\frac{\\partial L}{\\partial b_2}$\n",
    "4. $\\delta^{(1)}$ (hidden error signal)\n",
    "5. $\\frac{\\partial L}{\\partial w_1}$ and $\\frac{\\partial L}{\\partial b_1}$\n",
    "6. Updated weights after one step with $\\eta = 1.0$\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**1. Forward pass:**\n",
    "- $z_1 = w_1 \\cdot x + b_1 = 0.5 \\times 1.0 + 0 = 0.5$\n",
    "- $a_1 = \\sigma(0.5) \\approx 0.6225$\n",
    "- $z_2 = w_2 \\cdot a_1 + b_2 = -1.0 \\times 0.6225 + 0.5 = -0.1225$\n",
    "- $\\hat{y} = \\sigma(-0.1225) \\approx 0.4694$\n",
    "- $L = (0 - 0.4694)^2 = 0.2203$\n",
    "\n",
    "**2. Output error signal:**\n",
    "- $\\frac{\\partial L}{\\partial \\hat{y}} = -2(y - \\hat{y}) = -2(0 - 0.4694) = 0.9388$\n",
    "- $\\sigma'(z_2) = 0.4694 \\times 0.5306 = 0.2490$\n",
    "- $\\delta^{(2)} = 0.9388 \\times 0.2490 = 0.2338$\n",
    "\n",
    "**3. Output layer gradients:**\n",
    "- $\\frac{\\partial L}{\\partial w_2} = \\delta^{(2)} \\cdot a_1 = 0.2338 \\times 0.6225 = 0.1455$\n",
    "- $\\frac{\\partial L}{\\partial b_2} = \\delta^{(2)} = 0.2338$\n",
    "\n",
    "**4. Hidden error signal:**\n",
    "- $(w_2)^T \\cdot \\delta^{(2)} = -1.0 \\times 0.2338 = -0.2338$\n",
    "- $\\sigma'(z_1) = 0.6225 \\times 0.3775 = 0.2350$\n",
    "- $\\delta^{(1)} = -0.2338 \\times 0.2350 = -0.0549$\n",
    "\n",
    "**5. Hidden layer gradients:**\n",
    "- $\\frac{\\partial L}{\\partial w_1} = \\delta^{(1)} \\cdot x = -0.0549 \\times 1.0 = -0.0549$\n",
    "- $\\frac{\\partial L}{\\partial b_1} = \\delta^{(1)} = -0.0549$\n",
    "\n",
    "**6. Updated weights** ($\\eta = 1.0$):\n",
    "- $w_2 = -1.0 - 1.0 \\times 0.1455 = -1.1455$ (more negative ‚Üí pushes output lower ‚úì)\n",
    "- $b_2 = 0.5 - 1.0 \\times 0.2338 = 0.2662$ (lower bias ‚Üí pushes output lower ‚úì)\n",
    "- $w_1 = 0.5 - 1.0 \\times (-0.0549) = 0.5549$ (increases slightly)\n",
    "- $b_1 = 0.0 - 1.0 \\times (-0.0549) = 0.0549$ (increases slightly)\n",
    "\n",
    "All updates push the output toward 0 (the target). ‚úì\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Exercise 9.2: The Full Training Loop (Medium)\n",
    "\n",
    "Write a complete training function that trains an MLP and returns the loss history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(mlp, X, y, lr, n_epochs, print_every=1000):\n",
    "    \"\"\"\n",
    "    Complete training loop for an MLP.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mlp : MLP\n",
    "        Network to train\n",
    "    X : array, shape (n_input, N)\n",
    "        Training inputs\n",
    "    y : array, shape (n_output, N)\n",
    "        Training targets\n",
    "    lr : float\n",
    "        Learning rate\n",
    "    n_epochs : int\n",
    "        Number of epochs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    loss_history : list\n",
    "        Loss at each epoch\n",
    "    \"\"\"\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # TODO: Forward pass\n",
    "        ___\n",
    "        \n",
    "        # TODO: Compute and record loss\n",
    "        ___\n",
    "        \n",
    "        # TODO: Backward pass + update\n",
    "        ___\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            pred = (mlp.a2 > 0.5).astype(int)\n",
    "            acc = np.mean(pred == y) * 100\n",
    "            print(f\"Epoch {epoch:5d}: Loss = {loss:.6f}, Acc = {acc:.0f}%\")\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "# Test it\n",
    "mlp = MLP(n_input=2, n_hidden=4, n_output=1)\n",
    "losses = train_mlp(mlp, X_xor, y_xor, lr=2.0, n_epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77357d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0fc89",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def train_mlp(mlp, X, y, lr, n_epochs, print_every=1000):\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Forward pass\n",
    "        output = mlp.forward(X)\n",
    "        \n",
    "        # Compute and record loss\n",
    "        loss = mlp.compute_loss(y)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        # Backward pass + update\n",
    "        mlp.backward(X, y, lr)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            pred = (mlp.a2 > 0.5).astype(int)\n",
    "            acc = np.mean(pred == y) * 100\n",
    "            print(f\"Epoch {epoch:5d}: Loss = {loss:.6f}, Acc = {acc:.0f}%\")\n",
    "    \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f382c6c",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Exercise 9.3: Experimenting with Architecture (Medium)\n",
    "\n",
    "Train MLPs with different numbers of hidden neurons on XOR. Compare convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_experiment():\n",
    "    \"\"\"\n",
    "    Compare hidden layer sizes: [1, 2, 4, 8] neurons\n",
    "    \n",
    "    TODO:\n",
    "    1. For each size, create an MLP and train for 10000 epochs\n",
    "    2. Plot loss curves on the same graph\n",
    "    3. Answer: What's the minimum number of hidden neurons needed for XOR?\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for n_hidden in [1, 2, 4, 8]:\n",
    "        np.random.seed(42)\n",
    "        mlp = MLP(n_input=2, n_hidden=n_hidden, n_output=1)\n",
    "        losses = train_mlp(mlp, X_xor, y_xor, lr=2.0, n_epochs=10000, print_every=20000)\n",
    "        ax.plot(losses, label=f'{n_hidden} hidden neurons', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=14)\n",
    "    ax.set_ylabel('MSE Loss', fontsize=14)\n",
    "    ax.set_title('Effect of Hidden Layer Size on XOR', fontsize=16)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# architecture_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80377747",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. Can 1 hidden neuron solve XOR?\n",
    "2. What's the minimum number that works reliably?\n",
    "3. Do more neurons always help?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "1. **No!** 1 hidden neuron is equivalent to a single perceptron with a sigmoid ‚Äî it can only create a linear boundary. XOR requires at least 2 hidden neurons.\n",
    "\n",
    "2. **2 hidden neurons** is the theoretical minimum. In practice, 2 neurons *can* work but training may fail to converge depending on initialization. 4 neurons is more reliable.\n",
    "\n",
    "3. **More neurons help convergence** (more paths to a solution), but at the cost of more parameters. For a simple problem like XOR, 4 neurons is plenty ‚Äî 8 is overkill but converges faster.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Exercise 9.4: Beyond XOR ‚Äî Circle Dataset (Hard)\n",
    "\n",
    "Train an MLP to classify points inside vs outside a circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_data(n_samples=200, noise=0.1):\n",
    "    \"\"\"\n",
    "    Generate 2D data: class 1 if inside circle of radius 0.5, class 0 otherwise.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(2, n_samples) * 0.7\n",
    "    y = ((X[0] ** 2 + X[1] ** 2) < 0.5).astype(float).reshape(1, -1)\n",
    "    X += np.random.randn(2, n_samples) * noise\n",
    "    return X, y\n",
    "\n",
    "# TODO:\n",
    "# 1. Generate the circle dataset\n",
    "# 2. Create an MLP with an appropriate architecture\n",
    "# 3. Train it (experiment with learning rate and hidden size)\n",
    "# 4. Visualize the decision boundary\n",
    "# 5. How many hidden neurons do you need?\n",
    "\n",
    "X_circle, y_circle = generate_circle_data()\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X_circle[0, y_circle[0] == 0], X_circle[1, y_circle[0] == 0], \n",
    "            c='blue', alpha=0.5, label='Outside')\n",
    "plt.scatter(X_circle[0, y_circle[0] == 1], X_circle[1, y_circle[0] == 1], \n",
    "            c='red', alpha=0.5, label='Inside')\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.title('Circle Classification Dataset', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389b253",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Hints</summary>\n",
    "\n",
    "- A circle boundary is more complex than XOR ‚Äî you'll need more hidden neurons (try 8-16)\n",
    "- Learning rate around 1.0-2.0 works for sigmoid networks\n",
    "- Train for 5000-20000 epochs\n",
    "- The decision boundary should approximate a circle!\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train\n",
    "np.random.seed(42)\n",
    "mlp_circle = MLP(n_input=2, n_hidden=10, n_output=1)\n",
    "losses = train_mlp(mlp_circle, X_circle, y_circle, lr=1.5, n_epochs=15000, print_every=3000)\n",
    "\n",
    "# Visualize decision boundary\n",
    "x_range = np.linspace(-2, 2, 200)\n",
    "y_range = np.linspace(-2, 2, 200)\n",
    "X_grid, Y_grid = np.meshgrid(x_range, y_range)\n",
    "grid_input = np.vstack([X_grid.ravel(), Y_grid.ravel()])\n",
    "Z_grid = mlp_circle.forward(grid_input).reshape(X_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.contourf(X_grid, Y_grid, Z_grid, levels=[0, 0.5, 1], \n",
    "            colors=['#ADD8E6', '#FFCCCB'], alpha=0.4)\n",
    "plt.contour(X_grid, Y_grid, Z_grid, levels=[0.5], colors='black', linewidths=2)\n",
    "plt.scatter(X_circle[0, y_circle[0] == 0], X_circle[1, y_circle[0] == 0], \n",
    "            c='blue', alpha=0.5, label='Outside')\n",
    "plt.scatter(X_circle[0, y_circle[0] == 1], X_circle[1, y_circle[0] == 1], \n",
    "            c='red', alpha=0.5, label='Inside')\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.title('Learned Decision Boundary (Circle)', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0100d17",
   "metadata": {},
   "source": [
    "The network approximates a circular boundary using a combination of linear boundaries from the hidden neurons!\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Exercise 9.5: Gradient Checking Your Implementation (Hard)\n",
    "\n",
    "Run gradient checking on your MLP implementation with different network sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_gradient_check():\n",
    "    \"\"\"\n",
    "    Test gradient correctness for:\n",
    "    a) 2-2-1 network\n",
    "    b) 3-4-1 network\n",
    "    c) 2-3-2 network (2 outputs!)\n",
    "    \n",
    "    For each:\n",
    "    1. Create the network\n",
    "    2. Create a small random dataset (1-2 samples)\n",
    "    3. Run gradient_check()\n",
    "    4. Verify all pass with relative error < 1e-5\n",
    "    \"\"\"\n",
    "    configs = [\n",
    "        (2, 2, 1, \"2-2-1\"),\n",
    "        (3, 4, 1, \"3-4-1\"),\n",
    "        (2, 3, 2, \"2-3-2\"),\n",
    "    ]\n",
    "    \n",
    "    for n_in, n_hid, n_out, name in configs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing {name} network\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        mlp = MLP(n_in, n_hid, n_out)\n",
    "        X = np.random.randn(n_in, 2)   # 2 samples\n",
    "        y = np.random.rand(n_out, 2)   # random targets\n",
    "        \n",
    "        max_err = gradient_check(mlp, X, y)\n",
    "        print(f\"\\nResult for {name}: max error = {max_err:.2e} ‚Üí \"\n",
    "              f\"{'‚úì PASS' if max_err < 1e-5 else '‚úó FAIL'}\")\n",
    "\n",
    "# full_gradient_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac832321",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "‚úÖ **Chain Rule**: Compute derivatives through function compositions  \n",
    "‚úÖ **Computational Graphs**: Visualize forward and backward data flow  \n",
    "‚úÖ **Backpropagation Algorithm**: Forward pass ‚Üí store values ‚Üí backward pass ‚Üí update  \n",
    "‚úÖ **Error Signal $\\delta^{(l)}$**: Propagated backward through transposed weights  \n",
    "‚úÖ **XOR Training**: Network learned to solve XOR automatically!  \n",
    "‚úÖ **Gradient Checking**: Numerical verification of analytical gradients\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Backprop is just the chain rule**, applied systematically:\n",
    "   - Forward pass computes and stores intermediate values\n",
    "   - Backward pass multiplies local gradients along each path\n",
    "   - Each layer reuses the error signal from the layer above\n",
    "\n",
    "2. **The error signal flows backward:**\n",
    "   - Output layer: error comes directly from the loss\n",
    "   - Hidden layers: error is \"distributed\" through the transposed weight matrix\n",
    "   - Activation derivative acts as a \"gate\" at each layer\n",
    "\n",
    "3. **Always verify with gradient checking:**\n",
    "   - Numerical gradients are slow but simple and correct\n",
    "   - Compare before trusting a new backprop implementation\n",
    "   - Small relative error ($< 10^{-5}$) means your code is likely correct\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Session 7: Logistic Regression & Softmax**\n",
    "\n",
    "In the next session, we'll learn:\n",
    "- **Sigmoid for probabilities**: Interpreting outputs as class probabilities\n",
    "- **Cross-entropy loss**: A better loss function for classification\n",
    "- **Softmax**: Extending to multiple classes\n",
    "- **Complete classification pipeline**: From data to evaluated predictions\n",
    "\n",
    "**The goal:** Build proper classifiers that output probabilities, not just 0/1!\n",
    "\n",
    "### Before Next Session\n",
    "\n",
    "**Think about:**\n",
    "1. Our MLP uses MSE loss, but for classification we want to predict probabilities. What's wrong with MSE for probabilities?\n",
    "2. If the network outputs 0.99 for a class-0 sample, how should the loss penalize this? Should it be proportional to $(0 - 0.99)^2 = 0.98$ or something steeper?\n",
    "3. What if we have 5 possible classes instead of 2? How should the output layer look?\n",
    "\n",
    "**Optional reading:**\n",
    "- 3Blue1Brown: \"Backpropagation calculus\" (YouTube)\n",
    "- Chapter 6.5 of Goodfellow et al., \"Deep Learning\"\n",
    "\n",
    "---\n",
    "\n",
    "**End of Session 6** üéì\n",
    "\n",
    "**You now understand:**\n",
    "- ‚úÖ How the chain rule enables gradient computation through layers\n",
    "- ‚úÖ How backpropagation trains multi-layer networks\n",
    "- ‚úÖ How to verify your implementation with gradient checking\n",
    "\n",
    "**Next up:** Classification with cross-entropy and softmax! üöÄ"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
