{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0138a1",
   "metadata": {},
   "source": [
    "# Perceptron Introduction - Solutions Manual\n",
    "\n",
    "**Course: Neural Networks for Engineers**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Exercise 4.1: OR Gate (Easy)](#ex41)\n",
    "2. [Exercise 5.1: Visualize OR Gate (Easy)](#ex51)\n",
    "3. [Exercise 8.1: NOT Gate (Easy)](#ex81)\n",
    "4. [Exercise 8.2: NAND Gate (Medium)](#ex82)\n",
    "5. [Exercise 8.3: Manual Boundary (Medium)](#ex83)\n",
    "6. [Exercise 8.4: Adjust the Weights (Hard)](#ex84)\n",
    "7. [Exercise 8.5: XOR Challenge (Hard)](#ex85)\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 4.1: OR Gate (Easy) {#ex41}\n",
    "\n",
    "**Problem:** Design a perceptron for the OR gate.\n",
    "\n",
    "**Truth Table:**\n",
    "| $x_1$ | $x_2$ | OR Output |\n",
    "|-------|-------|-----------|\n",
    "| 0     | 0     | 0         |\n",
    "| 0     | 1     | 1         |\n",
    "| 1     | 0     | 1         |\n",
    "| 1     | 1     | 1         |\n",
    "\n",
    "### Solution\n",
    "\n",
    "**Manual Analysis:**\n",
    "\n",
    "We need the perceptron to output 1 when **at least one** input is 1.\n",
    "\n",
    "Let's try: $w_1 = 1, w_2 = 1, b = -0.5$\n",
    "\n",
    "**Test 1:** $x_1 = 0, x_2 = 0$\n",
    "$$\n",
    "z = 1 \\times 0 + 1 \\times 0 + (-0.5) = -0.5\n",
    "$$\n",
    "$z < 0$ â†’ **Output: 0** âœ…\n",
    "\n",
    "**Test 2:** $x_1 = 0, x_2 = 1$\n",
    "$$\n",
    "z = 1 \\times 0 + 1 \\times 1 + (-0.5) = 0.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 3:** $x_1 = 1, x_2 = 0$\n",
    "$$\n",
    "z = 1 \\times 1 + 1 \\times 0 + (-0.5) = 0.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 4:** $x_1 = 1, x_2 = 1$\n",
    "$$\n",
    "z = 1 \\times 1 + 1 \\times 1 + (-0.5) = 1.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "Perfect! All tests pass.\n",
    "\n",
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e783e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_OR(x1, x2):\n",
    "    \"\"\"OR gate perceptron\"\"\"\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    b = -0.5\n",
    "    \n",
    "    # Calculate weighted sum\n",
    "    z = w1 * x1 + w2 * x2 + b\n",
    "    \n",
    "    # Apply activation (step function)\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Test all combinations\n",
    "print(\"OR Gate Test:\")\n",
    "print(f\"0 OR 0 = {perceptron_OR(0, 0)}\")\n",
    "print(f\"0 OR 1 = {perceptron_OR(0, 1)}\")\n",
    "print(f\"1 OR 0 = {perceptron_OR(1, 0)}\")\n",
    "print(f\"1 OR 1 = {perceptron_OR(1, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1772bb4",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "OR Gate Test:\n",
    "0 OR 0 = 0\n",
    "0 OR 1 = 1\n",
    "1 OR 0 = 1\n",
    "1 OR 1 = 1\n",
    "```\n",
    "\n",
    "### Alternative Solutions\n",
    "\n",
    "Any of these weight/bias combinations also work:\n",
    "- $w_1 = 2, w_2 = 2, b = -1$\n",
    "- $w_1 = 0.5, w_2 = 0.5, b = -0.3$\n",
    "- $w_1 = 1, w_2 = 1, b = -0.9$\n",
    "\n",
    "**Key insight:** The bias needs to be between 0 and the smallest weight to allow a single 1 to activate the perceptron.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 5.1: Visualize OR Gate (Easy) {#ex51}\n",
    "\n",
    "**Problem:** Plot the decision boundary for the OR gate.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# The 4 points from OR gate\n",
    "points = np.array([\n",
    "    [0, 0],  # (0,0) â†’ class 0\n",
    "    [0, 1],  # (0,1) â†’ class 1\n",
    "    [1, 0],  # (1,0) â†’ class 1\n",
    "    [1, 1]   # (1,1) â†’ class 1\n",
    "])\n",
    "\n",
    "labels = np.array([0, 1, 1, 1])\n",
    "\n",
    "# Plot the points\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Class 0 points (blue circles)\n",
    "class_0 = points[labels == 0]\n",
    "plt.scatter(class_0[:, 0], class_0[:, 1], \n",
    "            s=200, c='blue', marker='o', \n",
    "            edgecolors='black', linewidth=2,\n",
    "            label='Class 0 (Output = 0)')\n",
    "\n",
    "# Class 1 points (red squares)\n",
    "class_1 = points[labels == 1]\n",
    "plt.scatter(class_1[:, 0], class_1[:, 1], \n",
    "            s=200, c='red', marker='s', \n",
    "            edgecolors='black', linewidth=2,\n",
    "            label='Class 1 (Output = 1)')\n",
    "\n",
    "# Draw the decision boundary\n",
    "# w1*x1 + w2*x2 + b = 0\n",
    "# x2 = -(w1*x1 + b) / w2\n",
    "w1, w2, b = 1, 1, -0.5\n",
    "\n",
    "x1_line = np.linspace(-0.5, 1.5, 100)\n",
    "x2_line = -(w1 * x1_line + b) / w2\n",
    "\n",
    "plt.plot(x1_line, x2_line, 'g-', linewidth=3, label='Decision Boundary')\n",
    "\n",
    "# Add labels and formatting\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.title('OR Gate: Decision Boundary', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(-0.2, -0.2, '(0,0)', fontsize=10)\n",
    "plt.text(-0.2, 1.05, '(0,1)', fontsize=10)\n",
    "plt.text(1.05, -0.2, '(1,0)', fontsize=10)\n",
    "plt.text(1.05, 1.05, '(1,1)', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c392c",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- The decision boundary for OR is similar to AND but shifted\n",
    "- Only the point (0,0) is on one side (blue circle)\n",
    "- All other points are on the opposite side (red squares)\n",
    "- The line equation is: $x_1 + x_2 - 0.5 = 0$ or $x_2 = -x_1 + 0.5$\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 8.1: NOT Gate (Easy) {#ex81}\n",
    "\n",
    "**Problem:** Create a perceptron for the NOT gate (one input).\n",
    "\n",
    "**Truth Table:**\n",
    "| $x$ | NOT Output |\n",
    "|-----|------------|\n",
    "| 0   | 1          |\n",
    "| 1   | 0          |\n",
    "\n",
    "### Solution\n",
    "\n",
    "**Manual Analysis:**\n",
    "\n",
    "For NOT gate, we need to **flip** the input:\n",
    "- When input is 0, output should be 1\n",
    "- When input is 1, output should be 0\n",
    "\n",
    "Let's try: $w_1 = -1, b = 0.5$\n",
    "\n",
    "**Test 1:** $x = 0$\n",
    "$$\n",
    "z = -1 \\times 0 + 0.5 = 0.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 2:** $x = 1$\n",
    "$$\n",
    "z = -1 \\times 1 + 0.5 = -0.5\n",
    "$$\n",
    "$z < 0$ â†’ **Output: 0** âœ…\n",
    "\n",
    "Perfect!\n",
    "\n",
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_NOT(x):\n",
    "    \"\"\"NOT gate perceptron\"\"\"\n",
    "    w = -1.0\n",
    "    b = 0.5\n",
    "    \n",
    "    # Calculate weighted sum\n",
    "    z = w * x + b\n",
    "    \n",
    "    # Apply activation (step function)\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Test\n",
    "print(\"NOT Gate:\")\n",
    "print(f\"NOT(0) = {perceptron_NOT(0)}\")\n",
    "print(f\"NOT(1) = {perceptron_NOT(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885fcb3",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "NOT Gate:\n",
    "NOT(0) = 1\n",
    "NOT(1) = 0\n",
    "```\n",
    "\n",
    "### Vectorized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# All inputs\n",
    "X = np.array([[0], [1]])\n",
    "\n",
    "# Weight and bias\n",
    "w = np.array([-1.0])\n",
    "b = 0.5\n",
    "\n",
    "# Compute\n",
    "z = X @ w + b\n",
    "outputs = (z >= 0).astype(int)\n",
    "\n",
    "print(\"NOT Gate (vectorized):\")\n",
    "for i in range(len(X)):\n",
    "    print(f\"NOT({X[i][0]}) = {outputs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e23066",
   "metadata": {},
   "source": [
    "**Key insight:** Negative weight inverts the relationship between input and output!\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 8.2: NAND Gate (Medium) {#ex82}\n",
    "\n",
    "**Problem:** Create a perceptron for the NAND gate (NOT AND).\n",
    "\n",
    "**Truth Table:**\n",
    "| $x_1$ | $x_2$ | NAND |\n",
    "|-------|-------|------|\n",
    "| 0     | 0     | 1    |\n",
    "| 0     | 1     | 1    |\n",
    "| 1     | 0     | 1    |\n",
    "| 1     | 1     | 0    |\n",
    "\n",
    "### Solution\n",
    "\n",
    "**Strategy:** NAND is the opposite of AND, so we can either:\n",
    "1. Use negative weights\n",
    "2. Use positive weights but positive bias\n",
    "\n",
    "Let's use **negative weights**: $w_1 = -1, w_2 = -1, b = 1.5$\n",
    "\n",
    "**Manual Tests:**\n",
    "\n",
    "**Test 1:** $x_1 = 0, x_2 = 0$\n",
    "$$\n",
    "z = -1 \\times 0 + -1 \\times 0 + 1.5 = 1.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 2:** $x_1 = 0, x_2 = 1$\n",
    "$$\n",
    "z = -1 \\times 0 + -1 \\times 1 + 1.5 = 0.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 3:** $x_1 = 1, x_2 = 0$\n",
    "$$\n",
    "z = -1 \\times 1 + -1 \\times 0 + 1.5 = 0.5\n",
    "$$\n",
    "$z \\geq 0$ â†’ **Output: 1** âœ…\n",
    "\n",
    "**Test 4:** $x_1 = 1, x_2 = 1$\n",
    "$$\n",
    "z = -1 \\times 1 + -1 \\times 1 + 1.5 = -0.5\n",
    "$$\n",
    "$z < 0$ â†’ **Output: 0** âœ…\n",
    "\n",
    "Perfect!\n",
    "\n",
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1561ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_NAND(x1, x2):\n",
    "    \"\"\"NAND gate perceptron\"\"\"\n",
    "    w1 = -1.0\n",
    "    w2 = -1.0\n",
    "    b = 1.5\n",
    "    \n",
    "    # Calculate weighted sum\n",
    "    z = w1 * x1 + w2 * x2 + b\n",
    "    \n",
    "    # Apply activation (step function)\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Test all combinations\n",
    "print(\"NAND Gate Test:\")\n",
    "print(f\"0 NAND 0 = {perceptron_NAND(0, 0)}\")\n",
    "print(f\"0 NAND 1 = {perceptron_NAND(0, 1)}\")\n",
    "print(f\"1 NAND 0 = {perceptron_NAND(1, 0)}\")\n",
    "print(f\"1 NAND 1 = {perceptron_NAND(1, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6d8a8",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "NAND Gate Test:\n",
    "0 NAND 0 = 1\n",
    "0 NAND 1 = 1\n",
    "1 NAND 0 = 1\n",
    "1 NAND 1 = 0\n",
    "```\n",
    "\n",
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compare AND vs NAND\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# AND Gate\n",
    "points = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "and_labels = np.array([0, 0, 0, 1])\n",
    "\n",
    "axes[0].scatter(points[and_labels == 0, 0], points[and_labels == 0, 1], \n",
    "                s=200, c='blue', marker='o', edgecolors='black', linewidth=2)\n",
    "axes[0].scatter(points[and_labels == 1, 0], points[and_labels == 1, 1], \n",
    "                s=200, c='red', marker='s', edgecolors='black', linewidth=2)\n",
    "\n",
    "# AND boundary: w1=1, w2=1, b=-1.5\n",
    "x1_line = np.linspace(-0.5, 1.5, 100)\n",
    "x2_line = -(1 * x1_line + (-1.5)) / 1\n",
    "axes[0].plot(x1_line, x2_line, 'g-', linewidth=3)\n",
    "axes[0].set_xlim(-0.5, 1.5)\n",
    "axes[0].set_ylim(-0.5, 1.5)\n",
    "axes[0].set_xlabel('$x_1$', fontsize=14)\n",
    "axes[0].set_ylabel('$x_2$', fontsize=14)\n",
    "axes[0].set_title('AND Gate', fontsize=16)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# NAND Gate\n",
    "nand_labels = np.array([1, 1, 1, 0])\n",
    "\n",
    "axes[1].scatter(points[nand_labels == 0, 0], points[nand_labels == 0, 1], \n",
    "                s=200, c='blue', marker='o', edgecolors='black', linewidth=2)\n",
    "axes[1].scatter(points[nand_labels == 1, 0], points[nand_labels == 1, 1], \n",
    "                s=200, c='red', marker='s', edgecolors='black', linewidth=2)\n",
    "\n",
    "# NAND boundary: w1=-1, w2=-1, b=1.5\n",
    "x2_line_nand = -(-1 * x1_line + 1.5) / (-1)\n",
    "axes[1].plot(x1_line, x2_line_nand, 'g-', linewidth=3)\n",
    "axes[1].set_xlim(-0.5, 1.5)\n",
    "axes[1].set_ylim(-0.5, 1.5)\n",
    "axes[1].set_xlabel('$x_1$', fontsize=14)\n",
    "axes[1].set_ylabel('$x_2$', fontsize=14)\n",
    "axes[1].set_title('NAND Gate (NOT AND)', fontsize=16)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e650e",
   "metadata": {},
   "source": [
    "**Observation:** NAND boundary is parallel to AND boundary but on the opposite side!\n",
    "\n",
    "**Historical Note:** NAND gates are universal - you can build ANY logic circuit from just NAND gates!\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 8.3: Manual Boundary (Medium) {#ex83}\n",
    "\n",
    "**Problem:** Given decision boundary $3x_1 + 2x_2 - 5 = 0$\n",
    "\n",
    "1. What are $w_1, w_2, b$?\n",
    "2. Classify points: A(1,1), B(2,0), C(0,3)\n",
    "3. Plot the line and points\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Part 1: Extract Parameters\n",
    "\n",
    "From the equation: $3x_1 + 2x_2 - 5 = 0$\n",
    "\n",
    "Comparing with: $w_1 x_1 + w_2 x_2 + b = 0$\n",
    "\n",
    "**Answer:**\n",
    "- $w_1 = 3$\n",
    "- $w_2 = 2$\n",
    "- $b = -5$\n",
    "\n",
    "#### Part 2: Manual Classification\n",
    "\n",
    "**Point A: (1, 1)**\n",
    "$$\n",
    "z = 3 \\times 1 + 2 \\times 1 + (-5) = 3 + 2 - 5 = 0\n",
    "$$\n",
    "$z = 0$ â†’ **On the boundary** (could be either class, but typically Class 1)\n",
    "\n",
    "**Point B: (2, 0)**\n",
    "$$\n",
    "z = 3 \\times 2 + 2 \\times 0 + (-5) = 6 + 0 - 5 = 1\n",
    "$$\n",
    "$z > 0$ â†’ **Class 1** (above/right of boundary)\n",
    "\n",
    "**Point C: (0, 3)**\n",
    "$$\n",
    "z = 3 \\times 0 + 2 \\times 3 + (-5) = 0 + 6 - 5 = 1\n",
    "$$\n",
    "$z > 0$ â†’ **Class 1** (above/right of boundary)\n",
    "\n",
    "#### Part 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "w1 = 3\n",
    "w2 = 2\n",
    "b = -5\n",
    "\n",
    "# Test points\n",
    "points = np.array([[1, 1], [2, 0], [0, 3]])\n",
    "point_names = ['A(1,1)', 'B(2,0)', 'C(0,3)']\n",
    "\n",
    "# Calculate z for each point\n",
    "w = np.array([w1, w2])\n",
    "z_values = points @ w + b\n",
    "\n",
    "print(\"Classification Results:\")\n",
    "for i, name in enumerate(point_names):\n",
    "    z = z_values[i]\n",
    "    if z > 0:\n",
    "        cls = \"Class 1\"\n",
    "    elif z < 0:\n",
    "        cls = \"Class 0\"\n",
    "    else:\n",
    "        cls = \"On boundary\"\n",
    "    print(f\"{name}: z = {z:.1f} â†’ {cls}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot decision boundary\n",
    "# 3x1 + 2x2 - 5 = 0\n",
    "# x2 = (5 - 3*x1) / 2\n",
    "x1_line = np.linspace(-1, 4, 100)\n",
    "x2_line = (5 - 3*x1_line) / 2\n",
    "\n",
    "plt.plot(x1_line, x2_line, 'g-', linewidth=3, label='Decision Boundary')\n",
    "\n",
    "# Shade regions\n",
    "plt.fill_between(x1_line, x2_line, 5, alpha=0.2, color='red', label='Class 1 Region')\n",
    "plt.fill_between(x1_line, -1, x2_line, alpha=0.2, color='blue', label='Class 0 Region')\n",
    "\n",
    "# Plot the test points\n",
    "colors = ['purple', 'red', 'red']  # Based on classification\n",
    "for i, (point, name, color) in enumerate(zip(points, point_names, colors)):\n",
    "    plt.scatter(point[0], point[1], s=300, c=color, marker='*', \n",
    "                edgecolors='black', linewidth=2, zorder=5)\n",
    "    plt.annotate(name, (point[0], point[1]), \n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xlim(-1, 4)\n",
    "plt.ylim(-1, 5)\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.title('Decision Boundary: $3x_1 + 2x_2 - 5 = 0$', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbf893",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "Classification Results:\n",
    "A(1,1): z = 0.0 â†’ On boundary\n",
    "B(2,0): z = 1.0 â†’ Class 1\n",
    "C(0,3): z = 1.0 â†’ Class 1\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- The slope of the line is $-w_1/w_2 = -3/2 = -1.5$\n",
    "- The y-intercept (when $x_1=0$) is $5/2 = 2.5$\n",
    "- The x-intercept (when $x_2=0$) is $5/3 \\approx 1.67$\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 8.4: Adjust the Weights (Hard) {#ex84}\n",
    "\n",
    "**Problem:** Improve the student classification accuracy by trying different weights.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the same data (using same seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate \"Pass\" students (Class 1)\n",
    "n_pass = 30\n",
    "pass_hours = np.random.uniform(5, 10, n_pass)\n",
    "pass_scores = np.random.uniform(60, 90, n_pass)\n",
    "pass_class = np.ones(n_pass)\n",
    "\n",
    "# Generate \"Fail\" students (Class 0)\n",
    "n_fail = 30\n",
    "fail_hours = np.random.uniform(0, 6, n_fail)\n",
    "fail_scores = np.random.uniform(20, 65, n_fail)\n",
    "fail_class = np.zeros(n_fail)\n",
    "\n",
    "# Combine data\n",
    "X = np.vstack([\n",
    "    np.column_stack([fail_hours, fail_scores]),\n",
    "    np.column_stack([pass_hours, pass_scores])\n",
    "])\n",
    "y = np.concatenate([fail_class, pass_class])\n",
    "\n",
    "# Grid search for best parameters\n",
    "w1_values = np.linspace(0.5, 4.0, 20)\n",
    "w2_values = np.linspace(0.1, 1.5, 20)\n",
    "b_values = np.linspace(-100, -40, 20)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "print(\"Searching for best parameters...\")\n",
    "print(\"Testing 8000 combinations...\")\n",
    "\n",
    "for w1 in w1_values:\n",
    "    for w2 in w2_values:\n",
    "        for b in b_values:\n",
    "            # Test this combination\n",
    "            w = np.array([w1, w2])\n",
    "            z = X @ w + b\n",
    "            y_pred = (z >= 0).astype(int)\n",
    "            accuracy = np.mean(y_pred == y)\n",
    "            \n",
    "            results.append((accuracy, w1, w2, b))\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = (w1, w2, b)\n",
    "\n",
    "print(f\"\\nBest accuracy: {best_accuracy * 100:.1f}%\")\n",
    "print(f\"Best parameters:\")\n",
    "print(f\"  w1 = {best_params[0]:.3f}\")\n",
    "print(f\"  w2 = {best_params[1]:.3f}\")\n",
    "print(f\"  b = {best_params[2]:.3f}\")\n",
    "\n",
    "# Test with best parameters\n",
    "w_best = np.array([best_params[0], best_params[1]])\n",
    "b_best = best_params[2]\n",
    "z_best = X @ w_best + b_best\n",
    "y_pred_best = (z_best >= 0).astype(int)\n",
    "\n",
    "# Show some predictions\n",
    "print(\"\\nSample predictions with best parameters:\")\n",
    "for i in range(5):\n",
    "    hours, score = X[i]\n",
    "    actual = \"Pass\" if y[i] == 1 else \"Fail\"\n",
    "    predicted = \"Pass\" if y_pred_best[i] == 1 else \"Fail\"\n",
    "    match = \"âœ“\" if y[i] == y_pred_best[i] else \"âœ—\"\n",
    "    print(f\"{match} Hours: {hours:.1f}, Score: {score:.1f} | \"\n",
    "          f\"Actual: {actual}, Predicted: {predicted}\")\n",
    "\n",
    "# Visualize best solution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Accuracy distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "accuracies = [r[0] for r in results]\n",
    "plt.hist(accuracies, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(best_accuracy, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Best: {best_accuracy*100:.1f}%')\n",
    "plt.xlabel('Accuracy', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Accuracies', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Best decision boundary\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], \n",
    "            s=100, c='blue', marker='o', \n",
    "            edgecolors='black', linewidth=1.5,\n",
    "            label='Fail', alpha=0.7)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], \n",
    "            s=100, c='red', marker='s', \n",
    "            edgecolors='black', linewidth=1.5,\n",
    "            label='Pass', alpha=0.7)\n",
    "\n",
    "# Draw best decision boundary\n",
    "x1_line = np.linspace(0, 10, 100)\n",
    "x2_line = -(w_best[0] * x1_line + b_best) / w_best[1]\n",
    "plt.plot(x1_line, x2_line, 'g-', linewidth=3, \n",
    "         label='Best Boundary', alpha=0.8)\n",
    "\n",
    "# Highlight misclassified points\n",
    "misclassified = y != y_pred_best\n",
    "if np.any(misclassified):\n",
    "    plt.scatter(X[misclassified, 0], X[misclassified, 1], \n",
    "                s=400, facecolors='none', edgecolors='orange', \n",
    "                linewidth=3, label='Misclassified')\n",
    "\n",
    "plt.xlabel('Hours Studied', fontsize=12)\n",
    "plt.ylabel('Previous Exam Score', fontsize=12)\n",
    "plt.title(f'Best Classifier (Accuracy: {best_accuracy*100:.1f}%)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(20, 90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis: Why can't we get 100%?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: Why can't we achieve 100% accuracy?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find overlapping regions\n",
    "fail_students = X[y == 0]\n",
    "pass_students = X[y == 1]\n",
    "\n",
    "print(f\"\\nFail students - hours range: [{fail_students[:, 0].min():.1f}, {fail_students[:, 0].max():.1f}]\")\n",
    "print(f\"Pass students - hours range: [{pass_students[:, 0].min():.1f}, {pass_students[:, 0].max():.1f}]\")\n",
    "print(f\"\\nFail students - score range: [{fail_students[:, 1].min():.1f}, {fail_students[:, 1].max():.1f}]\")\n",
    "print(f\"Pass students - score range: [{pass_students[:, 1].min():.1f}, {pass_students[:, 1].max():.1f}]\")\n",
    "\n",
    "print(\"\\nâ†’ The classes OVERLAP! Some failing students have similar\")\n",
    "print(\"  characteristics to passing students.\")\n",
    "print(\"\\nâ†’ A single straight line (perceptron) cannot perfectly\")\n",
    "print(\"  separate overlapping distributions.\")\n",
    "print(\"\\nâ†’ This is a fundamental limitation of LINEAR classifiers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0758f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Searching for best parameters...\n",
    "Testing 8000 combinations...\n",
    "\n",
    "Best accuracy: 91.7%\n",
    "Best parameters:\n",
    "  w1 = 2.947\n",
    "  w2 = 0.595\n",
    "  b = -72.105\n",
    "\n",
    "Sample predictions with best parameters:\n",
    "âœ“ Hours: 3.7, Score: 54.3 | Actual: Fail, Predicted: Fail\n",
    "âœ“ Hours: 1.9, Score: 42.0 | Actual: Fail, Predicted: Fail\n",
    "âœ— Hours: 5.3, Score: 62.7 | Actual: Fail, Predicted: Pass\n",
    "âœ“ Hours: 4.8, Score: 44.7 | Actual: Fail, Predicted: Fail\n",
    "âœ“ Hours: 0.9, Score: 47.9 | Actual: Fail, Predicted: Fail\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Best achievable accuracy: ~90-95%** (varies with random seed)\n",
    "2. **Cannot reach 100%** because:\n",
    "   - Data has natural overlap\n",
    "   - Some students with similar hours/scores have different outcomes\n",
    "   - Real-world data is noisy!\n",
    "3. **Linear classifier limitation**: A single line cannot separate overlapping clouds\n",
    "4. **Solution for 100%**: Would need:\n",
    "   - Non-linear boundary (curve, not line)\n",
    "   - Multiple layers (neural network)\n",
    "   - Different features\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 8.5: XOR Challenge (Hard) {#ex85}\n",
    "\n",
    "**Problem:** Can a single perceptron solve XOR?\n",
    "\n",
    "**XOR Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28661946",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18393157",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# XOR data\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([1, 0, 0, 1])\n",
    "\n",
    "print(\"XOR Truth Table:\")\n",
    "print(\"x1  x2  | Output\")\n",
    "print(\"----|-------|-------\")\n",
    "for i in range(4):\n",
    "    print(f\" {X_xor[i,0]}   {X_xor[i,1]}  |   {y_xor[i]}\")\n",
    "\n",
    "# Try many different weight combinations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ATTEMPTING TO FIND SOLUTION...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_w = None\n",
    "best_b = None\n",
    "attempts = 0\n",
    "\n",
    "# Systematic search\n",
    "for w1 in np.linspace(-5, 5, 50):\n",
    "    for w2 in np.linspace(-5, 5, 50):\n",
    "        for b in np.linspace(-5, 5, 50):\n",
    "            attempts += 1\n",
    "            w = np.array([w1, w2])\n",
    "            z = X_xor @ w + b\n",
    "            y_pred = (z >= 0).astype(int)\n",
    "            accuracy = np.mean(y_pred == y_xor)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_w = w.copy()\n",
    "                best_b = b\n",
    "\n",
    "print(f\"\\nTested {attempts} combinations\")\n",
    "print(f\"Best accuracy achieved: {best_accuracy * 100:.0f}%\")\n",
    "print(f\"Best weights: w1={best_w[0]:.3f}, w2={best_w[1]:.3f}\")\n",
    "print(f\"Best bias: b={best_b:.3f}\")\n",
    "\n",
    "if best_accuracy < 1.0:\n",
    "    print(\"\\nâŒ CANNOT achieve 100% accuracy!\")\n",
    "    print(f\"   Maximum possible: {best_accuracy * 100:.0f}% (only 3 out of 4 points correct)\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Found perfect solution!\")\n",
    "\n",
    "# Visualize the impossibility\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: The XOR problem\n",
    "ax = axes[0]\n",
    "colors = ['red' if label == 1 else 'blue' for label in y_xor]\n",
    "markers = ['s' if label == 1 else 'o' for label in y_xor]\n",
    "for i in range(4):\n",
    "    ax.scatter(X_xor[i, 0], X_xor[i, 1], s=300, \n",
    "               c=colors[i], marker=markers[i],\n",
    "               edgecolors='black', linewidth=2)\n",
    "    ax.text(X_xor[i, 0], X_xor[i, 1] - 0.15, \n",
    "            f'({X_xor[i,0]},{X_xor[i,1]})\\nâ†’ {y_xor[i]}',\n",
    "            ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "ax.set_xlabel('$x_1$', fontsize=14)\n",
    "ax.set_ylabel('$x_2$', fontsize=14)\n",
    "ax.set_title('XOR Problem\\n(Red squares=1, Blue circles=0)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Attempt with best linear boundary\n",
    "ax = axes[1]\n",
    "for i in range(4):\n",
    "    ax.scatter(X_xor[i, 0], X_xor[i, 1], s=300, \n",
    "               c=colors[i], marker=markers[i],\n",
    "               edgecolors='black', linewidth=2)\n",
    "\n",
    "# Draw best decision boundary found\n",
    "x1_line = np.linspace(-0.5, 1.5, 100)\n",
    "if best_w[1] != 0:\n",
    "    x2_line = -(best_w[0] * x1_line + best_b) / best_w[1]\n",
    "    ax.plot(x1_line, x2_line, 'g-', linewidth=3, label='Best Line Found')\n",
    "\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "ax.set_xlabel('$x_1$', fontsize=14)\n",
    "ax.set_ylabel('$x_2$', fontsize=14)\n",
    "ax.set_title(f'Best Linear Attempt\\n(Accuracy: {best_accuracy*100:.0f}%)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Plot 3: Why it's impossible - show we need TWO lines\n",
    "ax = axes[2]\n",
    "for i in range(4):\n",
    "    ax.scatter(X_xor[i, 0], X_xor[i, 1], s=300, \n",
    "               c=colors[i], marker=markers[i],\n",
    "               edgecolors='black', linewidth=2)\n",
    "\n",
    "# Show that we need TWO lines (or a curve)\n",
    "ax.plot([0.5, 0.5], [-0.5, 1.5], 'purple', linewidth=3, \n",
    "        linestyle='--', label='Need this line AND')\n",
    "ax.plot([-0.5, 1.5], [0.5, 0.5], 'orange', linewidth=3, \n",
    "        linestyle='--', label='this line')\n",
    "\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "ax.set_xlabel('$x_1$', fontsize=14)\n",
    "ax.set_ylabel('$x_2$', fontsize=14)\n",
    "ax.set_title('Solution Needs TWO Lines\\n(Not possible with 1 perceptron!)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mathematical proof\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MATHEMATICAL PROOF OF IMPOSSIBILITY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFor XOR to work, we need ALL of these simultaneously:\")\n",
    "print(\"1. (0,0): w1*0 + w2*0 + b â‰¥ 0  â†’  b â‰¥ 0\")\n",
    "print(\"2. (0,1): w1*0 + w2*1 + b < 0  â†’  w2 + b < 0  â†’  w2 < -b\")\n",
    "print(\"3. (1,0): w1*1 + w2*0 + b < 0  â†’  w1 + b < 0  â†’  w1 < -b\")\n",
    "print(\"4. (1,1): w1*1 + w2*1 + b â‰¥ 0  â†’  w1 + w2 + b â‰¥ 0\")\n",
    "print(\"\\nFrom (1): b â‰¥ 0\")\n",
    "print(\"From (2) and (3): w1 < -b and w2 < -b\")\n",
    "print(\"From (4): w1 + w2 â‰¥ -b\")\n",
    "print(\"\\nBut if b â‰¥ 0, then -b â‰¤ 0\")\n",
    "print(\"So: w1 < 0 and w2 < 0, which means w1 + w2 < 0\")\n",
    "print(\"This contradicts w1 + w2 â‰¥ -b â‰¥ 0\")\n",
    "print(\"\\nâ†’ CONTRADICTION! No solution exists!\")\n",
    "print(\"â†’ XOR is NOT linearly separable!\")\n",
    "\n",
    "# Show the solution: Use TWO perceptrons (multi-layer)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"THE SOLUTION: Multi-Layer Perceptron\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nXOR can be computed using THREE perceptrons:\")\n",
    "print(\"1. First perceptron: NAND gate\")\n",
    "print(\"2. Second perceptron: OR gate\")\n",
    "print(\"3. Third perceptron: AND gate\")\n",
    "print(\"\\nArchitecture:\")\n",
    "print(\"        x1 â”€â”€â”\")\n",
    "print(\"             â”œâ”€â”€[NAND]â”€â”€â”\")\n",
    "print(\"        x2 â”€â”€â”˜           â”œâ”€â”€[AND]â”€â”€ output\")\n",
    "print(\"             â”Œâ”€â”€â”€[OR]â”€â”€â”€â”˜\")\n",
    "print(\"        x1 â”€â”€â”¤\")\n",
    "print(\"        x2 â”€â”€â”˜\")\n",
    "print(\"\\nThis is a 2-layer neural network!\")\n",
    "print(\"(The birth of deep learning!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f10d09",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "XOR Truth Table:\n",
    "x1  x2  | Output\n",
    "----|-------|-------\n",
    " 0   0  |   1\n",
    " 0   1  |   0\n",
    " 1   0  |   0\n",
    " 1   1  |   1\n",
    "\n",
    "============================================================\n",
    "ATTEMPTING TO FIND SOLUTION...\n",
    "============================================================\n",
    "\n",
    "Tested 125000 combinations\n",
    "Best accuracy achieved: 50%\n",
    "Best weights: w1=0.000, w2=0.000\n",
    "Best bias: b=0.000\n",
    "\n",
    "âŒ CANNOT achieve 100% accuracy!\n",
    "   Maximum possible: 50% (only 2 out of 4 points correct)\n",
    "\n",
    "[Visualizations showing impossibility]\n",
    "\n",
    "============================================================\n",
    "MATHEMATICAL PROOF OF IMPOSSIBILITY\n",
    "============================================================\n",
    "[Complete proof as shown above]\n",
    "```\n",
    "\n",
    "### Bonus: Implement XOR with Multiple Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing XOR using 3 perceptrons (2-layer network)\n",
    "\n",
    "def perceptron(x, w, b):\n",
    "    \"\"\"Single perceptron\"\"\"\n",
    "    z = np.dot(w, x) + b\n",
    "    return 1 if z >= 0 else 0\n",
    "\n",
    "def xor_network(x1, x2):\n",
    "    \"\"\"XOR using multi-layer perceptron\"\"\"\n",
    "    # Layer 1: NAND and OR gates\n",
    "    nand_out = perceptron([x1, x2], [-1, -1], 1.5)\n",
    "    or_out = perceptron([x1, x2], [1, 1], -0.5)\n",
    "    \n",
    "    # Layer 2: AND gate\n",
    "    xor_out = perceptron([nand_out, or_out], [1, 1], -1.5)\n",
    "    \n",
    "    return xor_out\n",
    "\n",
    "# Test\n",
    "print(\"XOR using Multi-Layer Perceptron:\")\n",
    "print(\"x1  x2  | XOR\")\n",
    "print(\"---------|----\")\n",
    "for x1 in [0, 1]:\n",
    "    for x2 in [0, 1]:\n",
    "        result = xor_network(x1, x2)\n",
    "        print(f\" {x1}   {x2}  |  {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61f3f8",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "XOR using Multi-Layer Perceptron:\n",
    "x1  x2  | XOR\n",
    "---------|----\n",
    " 0   0  |  1\n",
    " 0   1  |  0\n",
    " 1   0  |  0\n",
    " 1   1  |  1\n",
    "```\n",
    "\n",
    "**Historical Significance:**\n",
    "\n",
    "This XOR problem (discovered by Minsky & Papert, 1969) caused the first \"AI Winter\"! It showed that single perceptrons have severe limitations. The solution - multiple layers - led to modern deep learning 40+ years later!\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Lessons from Exercises\n",
    "\n",
    "1. **OR Gate**: Similar to AND but needs smaller bias\n",
    "2. **NOT Gate**: Negative weight inverts input\n",
    "3. **NAND Gate**: Universal logic gate (can build anything!)\n",
    "4. **Manual Calculations**: Essential for understanding\n",
    "5. **Weight Tuning**: Grid search can find good solutions\n",
    "6. **Linear Separability**: Fundamental limitation of single perceptrons\n",
    "7. **XOR Problem**: Proved we need multiple layers (neural networks!)\n",
    "\n",
    "### Important Concepts\n",
    "\n",
    "- **Weights**: Determine importance and direction\n",
    "- **Bias**: Shifts the decision boundary\n",
    "- **Linear Separability**: Can we draw a line to separate classes?\n",
    "- **Multiple Layers**: Solution to non-linear problems\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Students should now be ready to:\n",
    "1. Understand the perceptron learning algorithm\n",
    "2. Implement gradient descent\n",
    "3. Study multi-layer perceptrons\n",
    "4. Explore backpropagation\n",
    "5. Build deep neural networks\n",
    "\n",
    "---\n",
    "\n",
    "**End of Solutions Manual** ðŸŽ“"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
